{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "um62ovjKLeqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "94bae139-4e1b-47d4-fe16-6738fe53ccf3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUf8Nm7dLsMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36881199-cce0-4d0f-b79c-38c3a0706982"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "%matplotlib inline  \n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import pickle \n",
        "import re #regular expression\n",
        "import tensorflow as tf\n",
        "from functools import reduce\n",
        "def raw_to_mel(audio, sampling_rate, window_size, hop_length, n_freqs):\n",
        "    \"\"\"Go from 1D numpy array containing audio waves to mel spectrogram.\n",
        "\n",
        "    Parameters:\n",
        "        audio: 1D numpy array containing the audio.\n",
        "        sampling_rate: Sampling rate of audio.\n",
        "        window_size: STFT window size.\n",
        "        hop_length: Distance between successive STFT windows.\n",
        "        n_freqs: Number of mel frequency bins.\n",
        "\n",
        "    Returns:\n",
        "        Processed spectrogram, bins x time.\n",
        "\n",
        "    \"\"\"    \n",
        "    spectro = librosa.stft(audio, n_fft=window_size, hop_length=hop_length,\n",
        "                           center=True)\n",
        "    power = np.abs(spectro)**2\n",
        "    mel = librosa.feature.melspectrogram(S=power, sr=sampling_rate,\n",
        "                                         n_mels=n_freqs)\n",
        "    logmel = np.log(mel + 1e-11)\n",
        "    return logmel\n",
        "\n",
        "def raw_to_pcen(audio, sampling_rate, window_size, hop_length, n_freqs):\n",
        "    \"\"\"Go from 1D numpy array containing audio waves to PCEN spectrogram.\n",
        "\n",
        "    Parameters might not be optimal...\n",
        "\n",
        "    Parameters:\n",
        "        audio: 1D numpy array containing the audio.\n",
        "        sampling_rate: Sampling rate of audio.\n",
        "        window_size: STFT window size.\n",
        "        hop_length: Distance between successive STFT windows.\n",
        "        n_freqs: Number of mel frequency bins.\n",
        "\n",
        "    Returns:\n",
        "        PCEN spectrogram, bins x time.\n",
        "\n",
        "    \"\"\"\n",
        "    spectro = np.abs(librosa.stft(audio, n_fft=window_size,\n",
        "                                  hop_length=hop_length, center=True))\n",
        "    mel = librosa.feature.melspectrogram(S=spectro, sr=sampling_rate,\n",
        "                                         n_mels=n_freqs)\n",
        "    pcen = librosa.pcen(mel, sr=sampling_rate, hop_length=hop_length,\n",
        "                        time_constant=0.285)\n",
        "    return pcen\n",
        "\n",
        "def chs_to_inds(char_list, mapping):\n",
        "    \"\"\"Helper to convert a list of characters to a list of corresponding indices.\n",
        "\n",
        "    Parameters:\n",
        "        char_list: List of characters (or string).\n",
        "        mapping: Dict mapping characters to indices.\n",
        "\n",
        "    Returns:\n",
        "        List of character indices.\n",
        "    \"\"\"\n",
        "    return [mapping[ch] for ch in char_list]\n",
        "  \n",
        "  \n",
        "def trim_audio(audio, sr, start, end):\n",
        "    \"\"\"start, end - in seconds (float)\n",
        "    Return:\n",
        "        Trimmed audio, None if out of boudaries\n",
        "    \"\"\"\n",
        "    assert start < end, \"End time step should be bigger then start time step.\"\n",
        "    audio_segment = audio[round(start*sr): round(end*sr)]\n",
        "    return audio_segment\n",
        "\n",
        "def mel_plot(S):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), #convert power to db\n",
        "                             y_axis='log',x_axis='time')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Mel spectrogram')\n",
        "    plt.tight_layout()\n",
        "    return plt.show()\n",
        "\n",
        "def audio_stack(audio_dir,audio_path, trim = True):\n",
        "    '''\n",
        "    If trim is True, silent region 2s before and after the audio will be removed\n",
        "    \n",
        "    Returns: \n",
        "        List of audio\n",
        "        Sampling rate\n",
        "        List of audio duration\n",
        "    '''\n",
        "    audio_list = [] #audio time-series\n",
        "    t_list = [] #time duration \n",
        "    for audio in audio_dir:\n",
        "        path = os.path.join(audio_path, audio)\n",
        "        y, sr = librosa.load(path)\n",
        "        if trim == True:\n",
        "            audio_length = librosa.get_duration(y=y, sr=sr)\n",
        "            y, sr = librosa.load(path, offset=2.0, duration = (audio_length -4.0))\n",
        "        audio_list.append(y)\n",
        "        t_list.append(librosa.get_duration(y=y, sr=sr))\n",
        "    \n",
        "    print('Sample rate: {} Hz'.format(sr)) #sample rate is same for all audio    \n",
        "    return audio_list, sr, t_list\n",
        "  \n",
        "train_audio_path=\"/content/gdrive/My Drive/DAMP\"\n",
        "audio_dir_train = sorted(os.listdir(train_audio_path))\n",
        "audio_list_train, sr_train, t_list_train = audio_stack(audio_dir_train,train_audio_path)\n",
        "\n",
        "\n",
        "\n",
        "def remove_header(read_txt, write_txt):\n",
        "    '''\n",
        "    Remove header from lyrics transcription.\n",
        "    \n",
        "    Parameters:\n",
        "        read_txt: Lyrics transcription text file that contains header\n",
        "        write_txt: New txt file with lyrics without header\n",
        "    '''\n",
        "   \n",
        "    f = open(read_txt, 'r')\n",
        "    l = []\n",
        "    k = []\n",
        "    write_file = open(write_txt,'w')\n",
        "    for x in f:\n",
        "        l.append((x.split(' ',1)[0])) #headers before the true lyrics start\n",
        "        k.append((x.split(' ',1)[1])) #lyrics transcription without headers\n",
        "    #Example\n",
        "#     print('Headers:',l[0])\n",
        "#     print('Lyrics without headers:', k[0])\n",
        "    \n",
        "    for i in range(len(k)):    \n",
        "        write_file.write(k[i])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def map_text2char(read_txt):\n",
        "    \n",
        "    '''\n",
        "    Remove special characters/symbols and convert all characters into lower case\n",
        "    Parameters:\n",
        "        read_txt: Txt file to be input\n",
        "    '''\n",
        "    chars = set()\n",
        "    with open(read_txt) as text:\n",
        "        for line in text:\n",
        "            line = re.sub('[^A-Za-z\\']+', ' ', line).lower()\n",
        "            chars.update(set(line))\n",
        "            #print(chars)\n",
        "            #print(range(3, len(chars)+3))\n",
        "            mapping = dict(zip(chars, range(3, len(chars)+3)))\n",
        "            #print(mapping)\n",
        "            mapping[\"<PAD>\"] = 0\n",
        "            mapping[\"<S>\"] = 1\n",
        "            mapping[\"</S>\"] = 2\n",
        "\n",
        "        #save vocab\n",
        "        with open('damp_vocab', 'wb') as fp:\n",
        "            pickle.dump(mapping, fp)\n",
        "        \n",
        "        return mapping\n",
        "\n",
        "def enumerate_lines(file):\n",
        "    with open(file) as text:\n",
        "        return [line for i, line in enumerate(text)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample rate: 22050 Hz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiUldCEbMbGS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "cdeca7de-efd5-4408-c7d9-b3d66f93fd3e"
      },
      "source": [
        "train_remove_header = remove_header('/content/gdrive/My Drive/train.txt','DAMP_train_lyrics.txt')\n",
        "train_enum = enumerate_lines('DAMP_train_lyrics.txt')\n",
        "train_mapping = map_text2char('DAMP_train_lyrics.txt')\n",
        "#test_mapping= map_text2char(test_enum[0])\n",
        "print(train_mapping)\n",
        "print(train_enum[0])\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    logmel = raw_to_mel(audio_list_train[i], sr_train, window_size=2048, hop_length=512, n_freqs=128)\n",
        "    for line in train_enum[i]:\n",
        "        line = re.sub('[^A-Za-z0-9\\']+', ' ', line).lower()\n",
        "        mapped = [train_mapping[\"<S>\"]] + chs_to_inds(line, train_mapping) + [train_mapping[\"</S>\"]]\n",
        "        print(line,end='')\n",
        "    print(logmel.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'t': 3, 'd': 4, 'c': 5, 'z': 6, 'l': 7, 'r': 8, 'k': 9, 'u': 10, 'j': 11, 'e': 12, 'g': 13, 'w': 14, 'm': 15, 'f': 16, \"'\": 17, 'n': 18, 'x': 19, 'v': 20, 'o': 21, 'q': 22, 'b': 23, 'i': 24, 's': 25, ' ': 26, 'p': 27, 'h': 28, 'a': 29, 'y': 30, '<PAD>': 0, '<S>': 1, '</S>': 2}\n",
            "IT'S BIGGER IT'S BIGGER THAN YOU AND YOU ARE NOT ME \n",
            "\n",
            "it's bigger it's bigger than you and you are not me  (128, 339)\n",
            "the lengths that i will go to the distance in your eyes oh no  (128, 464)\n",
            "set it up that's me in the corner that's me in the spotlight  (128, 558)\n",
            "spotlight losing my religion trying to keep a view and i don't know if i can do it  (128, 352)\n",
            "much i haven't said enough i thought that i heard you laughing  (128, 361)\n",
            "i thought that i heard you sing i think i thought i saw you try  (128, 525)\n",
            "every whisper of every waking hour i'm choosing my confessions  (128, 394)\n",
            "brought me to my knees failed what if all these fantasies come flailing around  (128, 408)\n",
            "now i've said too much i thought that i heard you laughing  (128, 518)\n",
            "i thought that i heard you sing i think i thought i saw you try  (128, 567)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stj95N6iMuCU"
      },
      "source": [
        "def create_tfrecords(out_filename, enum_list, audio_list, path_to_save=''):\n",
        "    \"\"\"Process audio files and annotations into TFRecords data file.\n",
        "\n",
        "    Parameters:\n",
        "        out_filename: 1D numpy array containing the audio.\n",
        "        enum_list: enumarate list of text line from lyrics script.\n",
        "        audio_list: list of input audio (test/train)\n",
        "        path_audio: Path to retrieved raw data.\n",
        "    \"\"\"\n",
        "    if path_to_save:\n",
        "        print(\"tfrecords will be saved here:\", path_to_save)\n",
        "        if not os.path.exists(path_to_save):\n",
        "            os.makedirs(path_to_save)\n",
        "        target_path = path_to_save\n",
        "    else:\n",
        "        print(\"Current working directory is used to save tfrecords:\", os.getcwd())\n",
        "        target_path = os.getcwd()\n",
        "        \n",
        "    with tf.python_io.TFRecordWriter(os.path.join(target_path, out_filename + \".tfrecords\")) as writer:\n",
        "        for i in range(len(audio_list)):\n",
        "            logmel = raw_to_mel(audio_list[i], sr_train, window_size = 2048, hop_length = 512, n_freqs = 128)\n",
        "            for line in enum_list[i]:\n",
        "                line = re.sub('[^A-Za-z0-9\\']+', ' ', line).lower()\n",
        "                mapped_seq = [train_mapping[\"<S>\"]] + chs_to_inds(line, train_mapping) + [train_mapping[\"</S>\"]]    \n",
        "\n",
        "                flatten_logmel_shape = reduce(lambda x, y: x * y, logmel.shape)\n",
        "                flatten_logmel = np.reshape(logmel, [flatten_logmel_shape, ])\n",
        "\n",
        "            tfex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                \"seq\": tf.train.Feature(int64_list=tf.train.Int64List(value=mapped_seq)),\n",
        "                \"mel\": tf.train.Feature(float_list=tf.train.FloatList(value=flatten_logmel)),\n",
        "                \"mel_shape\": tf.train.Feature(int64_list=tf.train.Int64List(value=logmel.shape))\n",
        "\n",
        "            }))\n",
        "            writer.write(tfex.SerializeToString())\n",
        "        print(\"Saved to: {}\".format(os.path.join(target_path, out_filename + \".tfrecords\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdWaGJbtM1Dd"
      },
      "source": [
        "def parse_seq(example_proto):\n",
        "    \"\"\"\n",
        "    Needed to read the stored .tfrecords data -- import this in your\n",
        "    training script.\n",
        "    \n",
        "    Parameters:\n",
        "        example_proto: Protocol buffer of single example.\n",
        "    Return: \n",
        "        Tuple of Tensors containing the logmel spectogram and parsed sequence.\n",
        "    \"\"\"\n",
        "    features = {\"seq\": tf.VarLenFeature(tf.int64),\n",
        "                \"mel\": tf.VarLenFeature(tf.float32),\n",
        "                \"mel_shape\": tf.FixedLenFeature([2], tf.int64)}\n",
        "    parsed_features = tf.parse_single_example(example_proto, features)\n",
        "    sparse_seq = parsed_features[\"seq\"]\n",
        "    sparse_mel= parsed_features[\"mel\"]\n",
        "    mel = tf.sparse_to_dense(sparse_mel.indices, sparse_mel.dense_shape, sparse_mel.values)\n",
        "    mel = tf.reshape(mel, parsed_features[\"mel_shape\"])\n",
        "    seq = tf.sparse_to_dense(sparse_seq.indices, sparse_seq.dense_shape, sparse_seq.values)\n",
        "    return mel, seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--0f9oWvRm_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3bc0e559-a61e-4477-c24c-be97eea63acc"
      },
      "source": [
        "#out_filename=DAMP1.tfrecords\n",
        "create_tfrecords('train', train_enum, audio_list_train, \"/content/gdrive/My Drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfrecords will be saved here: /content/gdrive/My Drive\n",
            "Saved to: /content/gdrive/My Drive/train.tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cgsS-sgM8gd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        },
        "outputId": "ffc9ec19-066a-45fa-9cb7-99c0d8d65044"
      },
      "source": [
        "\n",
        "out_path_training = \"/content/gdrive/My Drive/train\"\n",
        "data = tf.data.TFRecordDataset(out_path_training + \".tfrecords\")\n",
        "data = data.map(lambda x: parse_seq(x))\n",
        "data = data.padded_batch(4, padded_shapes=([128, None],[None]))\n",
        "\n",
        "iterator = data.make_initializable_iterator()\n",
        "next_batch = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(iterator.initializer)\n",
        "    for i in range(1):\n",
        "        example = sess.run([next_batch])\n",
        "        print(example)\n",
        "        print(\"Mel spectr. - {}\".format(example[0][0].shape), \"Sequence - {}\".format(example[0][1].shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(array([[[ -4.8699765,  -4.2327137,  -4.8743734, ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [ -3.7408812,  -3.2661116,  -3.6742923, ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [ -1.6931499,  -2.327741 ,  -2.8682632, ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        ...,\n",
            "        [-14.530863 , -15.9171   , -25.328186 , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [-14.555361 , -15.941596 , -25.32828  , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [-14.570981 , -15.957215 , -25.328272 , ...,   0.       ,\n",
            "           0.       ,   0.       ]],\n",
            "\n",
            "       [[ -4.7134166,  -5.2503133,  -4.632083 , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [ -3.0904372,  -3.3358045,  -2.8856297, ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [ -3.5631924,  -3.182612 ,  -3.3891728, ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        ...,\n",
            "        [-23.194237 , -24.276678 , -25.32822  , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [-23.210888 , -24.288929 , -25.328146 , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [-23.221601 , -24.296762 , -25.32802  , ...,   0.       ,\n",
            "           0.       ,   0.       ]],\n",
            "\n",
            "       [[ -4.59003  ,  -4.369883 ,  -5.1279073, ...,  -4.837617 ,\n",
            "          -3.705152 ,  -3.3880734],\n",
            "        [ -3.2508316,  -3.8119643,  -4.5713296, ...,  -3.9540699,\n",
            "          -3.5945368,  -3.0628726],\n",
            "        [ -4.295577 ,  -4.3462553,  -4.4449806, ...,  -4.161866 ,\n",
            "          -3.9981358,  -3.0212443],\n",
            "        ...,\n",
            "        [-23.80944  , -24.690744 , -25.326944 , ..., -25.327986 ,\n",
            "         -20.92265  , -10.827324 ],\n",
            "        [-23.822624 , -24.6987   , -25.326712 , ..., -25.328028 ,\n",
            "         -20.93731  , -10.842198 ],\n",
            "        [-23.830896 , -24.703655 , -25.326538 , ..., -25.328117 ,\n",
            "         -20.946724 , -10.851773 ]],\n",
            "\n",
            "       [[ -4.2534537,  -4.354683 ,  -5.4906616, ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [ -3.156252 ,  -3.911028 ,  -4.61698  , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [ -3.1020803,  -3.484788 ,  -4.981688 , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        ...,\n",
            "        [-23.809402 , -24.69076  , -25.328297 , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [-23.822653 , -24.698748 , -25.32828  , ...,   0.       ,\n",
            "           0.       ,   0.       ],\n",
            "        [-23.830873 , -24.703672 , -25.328312 , ...,   0.       ,\n",
            "           0.       ,   0.       ]]], dtype=float32), array([[ 1, 26,  2],\n",
            "       [ 1, 26,  2],\n",
            "       [ 1, 26,  2],\n",
            "       [ 1, 26,  2]]))]\n",
            "Mel spectr. - (4, 128, 558) Sequence - (4, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmkGDoQmov9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc410bcb-e476-472b-c454-2fc369014643"
      },
      "source": [
        "print(len(audio_list_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHvT-fWtnz7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "66e2c353-0e94-46c0-d362-e673df745b57"
      },
      "source": [
        "def convert_to_numpy(input, output_path,npy_name):\n",
        "    input=np.asarray(input)\n",
        "    outputfilepath=os.path.join(output_path,npy_name)\n",
        "    np.save(outputfilepath +'.npy', input)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n    os.mkdir(output_path)  \\n    new_img_list = save(img_list, img_affine, output_path, label)\\n    images = three_to_two(path = output_path + '/*')\\n    \\n    if label=='FALSE':\\n        img = min_max_norm(images)\\n        np.save(npy_name+'.npy', img)\\n    else:\\n        img_lbl = label_outliers(images)\\n        np.save(npy_name+'.npy', img_lbl)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}